{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Task 1\n",
    "\n",
    "---\n",
    "\n",
    "## Web scraping and analysis\n",
    "\n",
    "This Jupyter notebook includes some code to get you started with web scraping. We will use a package called `BeautifulSoup` to collect the data from the web. Once you've collected your data and saved it into a local `.csv` file you should start with your analysis.\n",
    "\n",
    "### Scraping data from Skytrax\n",
    "\n",
    "If you visit [https://www.airlinequality.com] you can see that there is a lot of data there. For this task, we are only interested in reviews related to British Airways and the Airline itself.\n",
    "\n",
    "If you navigate to this link: [https://www.airlinequality.com/airline-reviews/british-airways] you will see this data. Now, we can use `Python` and `BeautifulSoup` to collect all the links to the reviews and then to collect the text data on each of the individual review links."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests\n",
    "from bs4 import BeautifulSoup\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Data want to collect\n",
    "\n",
    "review = []    # Empty list to store reviews     \n",
    "\n",
    "date = []       # Empty list to store date of review\n",
    "\n",
    "country = []    # Empty list to store country of a reviwer\n",
    "\n",
    "rating = []     # Empty list to store star rating"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scraping page 1\n",
      "   ---> 100 total reviews\n",
      "   ---> 100 total date\n",
      "   ---> 100 total country\n",
      "Scraping page 2\n",
      "   ---> 200 total reviews\n",
      "   ---> 200 total date\n",
      "   ---> 200 total country\n",
      "Scraping page 3\n",
      "   ---> 300 total reviews\n",
      "   ---> 300 total date\n",
      "   ---> 300 total country\n",
      "Scraping page 4\n",
      "   ---> 400 total reviews\n",
      "   ---> 400 total date\n",
      "   ---> 400 total country\n",
      "Scraping page 5\n",
      "   ---> 500 total reviews\n",
      "   ---> 500 total date\n",
      "   ---> 500 total country\n",
      "Scraping page 6\n",
      "   ---> 600 total reviews\n",
      "   ---> 600 total date\n",
      "   ---> 600 total country\n",
      "Scraping page 7\n",
      "   ---> 700 total reviews\n",
      "   ---> 700 total date\n",
      "   ---> 700 total country\n",
      "Scraping page 8\n",
      "   ---> 800 total reviews\n",
      "   ---> 800 total date\n",
      "   ---> 800 total country\n",
      "Scraping page 9\n",
      "   ---> 900 total reviews\n",
      "   ---> 900 total date\n",
      "   ---> 900 total country\n",
      "Scraping page 10\n",
      "   ---> 1000 total reviews\n",
      "   ---> 1000 total date\n",
      "   ---> 1000 total country\n"
     ]
    }
   ],
   "source": [
    "base_url = \"https://www.airlinequality.com/airline-reviews/british-airways\"\n",
    "pages = 10\n",
    "page_size = 100\n",
    "\n",
    "for i in range(1, pages + 1):\n",
    "    print(f\"Scraping page {i}\")\n",
    "\n",
    "    # Create URL to collect links from paginated data\n",
    "    url = f\"{base_url}/page/{i}/?sortby=post_date%3ADesc&pagesize={page_size}\"\n",
    "\n",
    "    # Collect HTML data from this page\n",
    "    response = requests.get(url)\n",
    "\n",
    "    # Parse content\n",
    "    content = response.content\n",
    "    parsed_content = BeautifulSoup(content, 'html.parser')\n",
    "    \n",
    "    # collect all the reviwes from the pages\n",
    "    for para in parsed_content.find_all(\"div\", class_ = \"text_content\"):\n",
    "        review.append(para.get_text())\n",
    "    print(f\"   ---> {len(review)} total reviews\")\n",
    "\n",
    "    # collect the dates of the review\n",
    "    for para in parsed_content.find_all(\"time\"):\n",
    "        date.append(para.get_text())\n",
    "    print(f\"   ---> {len(date)} total date\")\n",
    "\n",
    "    # collect the country name of the reviewers\n",
    "    for para in parsed_content.find_all(\"h3\"):\n",
    "        country.append(para.span.next_sibling.text.strip(\" ()\"))\n",
    "    print(f\"   ---> {len(country)} total country\")\n",
    "\n",
    "    # colect the rating given by the reviewers\n",
    "    for para in parsed_content.find_all(\"div\", class_ = \"rating-10\"):\n",
    "        rating.append(para.span.text)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reviews</th>\n",
       "      <th>date</th>\n",
       "      <th>country</th>\n",
       "      <th>rating</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Not Verified | Regarding the aircraft and seat...</td>\n",
       "      <td>28th April 2023</td>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>\\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Not Verified | I travelled with British Airway...</td>\n",
       "      <td>26th April 2023</td>\n",
       "      <td>Sweden</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Not Verified |  Food was lousy. Who ever is pl...</td>\n",
       "      <td>24th April 2023</td>\n",
       "      <td>United States</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>✅ Trip Verified | Had the worst experience. Th...</td>\n",
       "      <td>24th April 2023</td>\n",
       "      <td>Canada</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>✅ Trip Verified |  The ground staff were not h...</td>\n",
       "      <td>23rd April 2023</td>\n",
       "      <td>Ireland</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             reviews             date  \\\n",
       "0  Not Verified | Regarding the aircraft and seat...  28th April 2023   \n",
       "1  Not Verified | I travelled with British Airway...  26th April 2023   \n",
       "2  Not Verified |  Food was lousy. Who ever is pl...  24th April 2023   \n",
       "3  ✅ Trip Verified | Had the worst experience. Th...  24th April 2023   \n",
       "4  ✅ Trip Verified |  The ground staff were not h...  23rd April 2023   \n",
       "\n",
       "          country                         rating  \n",
       "0  United Kingdom  \\n\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t\\t5  \n",
       "1          Sweden                              5  \n",
       "2   United States                              1  \n",
       "3          Canada                              2  \n",
       "4         Ireland                              1  "
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.DataFrame()\n",
    "df[\"reviews\"] = pd.Series(review)\n",
    "df[\"date\"] = pd.Series(date)\n",
    "df[\"country\"] = pd.Series(country)\n",
    "df[\"rating\"] = pd.Series(rating)\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv(\"BA_reviews.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Congratulations! Now you have your dataset for this task! The loops above collected 1000 reviews by iterating through the paginated pages on the website. However, if you want to collect more data, try increasing the number of pages!\n",
    "\n",
    " The next thing that you should do is clean this data to remove any unnecessary text from each of the rows. For example, \"✅ Trip Verified\" can be removed from each row if it exists, as it's not relevant to what we want to investigate."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.9.13 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "4f7924c4c56b083e0e50eadfe7ef592a7a8ef70df33a0047f82280e6be1afe15"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
